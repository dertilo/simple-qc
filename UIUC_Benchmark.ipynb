{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UIUC Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('pt')\n",
    "create_features(['bow'], dataset['train'], dataset['test'])\n",
    "models = create_models(['svm_linear'])\n",
    "X = np.array([list(x) for x in dataset['train']['bow'].values])\n",
    "y = dataset['train']['class'].values\n",
    "X_ = np.array([list(x) for x in dataset['test']['bow'].values])\n",
    "y_ = dataset['test']['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  svm_linear .....\n",
      "Run time benchmark: 0.7749648094177246\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion</th>\n",
       "      <th>datetime</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>f1</th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>test_time</th>\n",
       "      <th>train_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776</td>\n",
       "      <td>[[3, 2, 0, 0, 0, 0], [6, 131, 25, 4, 15, 15], ...</td>\n",
       "      <td>2019-03-28 16:10:05.544153</td>\n",
       "      <td>0.031757</td>\n",
       "      <td>0.721988</td>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.698136</td>\n",
       "      <td>0.774230</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816</td>\n",
       "      <td>[[3, 0, 0, 0, 0, 0], [6, 130, 21, 4, 13, 6], [...</td>\n",
       "      <td>2019-03-28 16:10:05.643786</td>\n",
       "      <td>0.082604</td>\n",
       "      <td>0.762654</td>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.732438</td>\n",
       "      <td>0.858675</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.834</td>\n",
       "      <td>[[3, 2, 0, 0, 0, 0], [6, 129, 16, 2, 8, 4], [0...</td>\n",
       "      <td>2019-03-28 16:10:05.781466</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.769136</td>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.751979</td>\n",
       "      <td>0.803127</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850</td>\n",
       "      <td>[[4, 2, 0, 0, 0, 0], [5, 130, 18, 3, 6, 5], [0...</td>\n",
       "      <td>2019-03-28 16:10:05.989715</td>\n",
       "      <td>0.188642</td>\n",
       "      <td>0.800910</td>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.782601</td>\n",
       "      <td>0.831609</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.852</td>\n",
       "      <td>[[5, 2, 0, 0, 0, 0], [4, 128, 16, 2, 7, 4], [0...</td>\n",
       "      <td>2019-03-28 16:10:06.266016</td>\n",
       "      <td>0.255941</td>\n",
       "      <td>0.815029</td>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.801578</td>\n",
       "      <td>0.835882</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>5500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy                                          confusion  \\\n",
       "0     0.776  [[3, 2, 0, 0, 0, 0], [6, 131, 25, 4, 15, 15], ...   \n",
       "0     0.816  [[3, 0, 0, 0, 0, 0], [6, 130, 21, 4, 13, 6], [...   \n",
       "0     0.834  [[3, 2, 0, 0, 0, 0], [6, 129, 16, 2, 8, 4], [0...   \n",
       "0     0.850  [[4, 2, 0, 0, 0, 0], [5, 130, 18, 3, 6, 5], [0...   \n",
       "0     0.852  [[5, 2, 0, 0, 0, 0], [4, 128, 16, 2, 7, 4], [0...   \n",
       "\n",
       "                    datetime  execution_time        f1       model  precision  \\\n",
       "0 2019-03-28 16:10:05.544153        0.031757  0.721988  svm_linear   0.698136   \n",
       "0 2019-03-28 16:10:05.643786        0.082604  0.762654  svm_linear   0.732438   \n",
       "0 2019-03-28 16:10:05.781466        0.118417  0.769136  svm_linear   0.751979   \n",
       "0 2019-03-28 16:10:05.989715        0.188642  0.800910  svm_linear   0.782601   \n",
       "0 2019-03-28 16:10:06.266016        0.255941  0.815029  svm_linear   0.801578   \n",
       "\n",
       "     recall  test_time  train_size  \n",
       "0  0.774230   0.005424        1000  \n",
       "0  0.858675   0.004861        2000  \n",
       "0  0.803127   0.004499        3000  \n",
       "0  0.831609   0.004568        4000  \n",
       "0  0.835882   0.004606        5500  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_benchmark(models, X, y, X_, y_, sizes_train=[1000, 2000, 3000, 4000, 5500], save='results/pt_svm_bow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5452, 15)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(language):\n",
    "    # language: 'en', 'pt', 'es'\n",
    "    dataset = {\n",
    "        'train': pd.read_csv('datasets/UIUC_' + language + '/train.csv'),\n",
    "        'test': pd.read_csv('datasets/UIUC_' + language + '/test.csv'),\n",
    "    }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # features: ['bow', ]\n",
    "def create_features(features, df_train_, df_test_):\n",
    "    for feature in features:\n",
    "        create_feature(feature, df_train_, df_test_)\n",
    "        \n",
    "def create_feature(feature, df_train_, df_test_):\n",
    "    if feature == 'bow':\n",
    "        model = CountVectorizer(analyzer='word', strip_accents=None, \n",
    "                                ngram_range=(1, 1), lowercase=True, \n",
    "                                max_features=5000)\n",
    "        model.fit(pd.concat([df_train_['question'], df_test_['question']]))\n",
    "        ret = model.transform(df_train_['question']).toarray()\n",
    "        df_train_['bow'] = [x for x in ret]\n",
    "        ret = model.transform(df_test_['question']).toarray()\n",
    "        df_test_['bow'] = [x for x in ret]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create supervised models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(models):\n",
    "    ret = []\n",
    "    for model in models:\n",
    "        m = create_model(model)\n",
    "        if m is not None:\n",
    "            ret.append({'name': model, 'model': m})\n",
    "    return ret\n",
    "    \n",
    "def create_model(model):\n",
    "    if model == 'svm_linear':\n",
    "        return svm_linear\n",
    "    return None\n",
    "\n",
    "def svm_linear():\n",
    "\n",
    "    return LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(models, X, y, x_test, y_test, save='default.csv', sizes_train=[], start_results=None, metric_average=\"macro\"):\n",
    "    \n",
    "    start_benchmark = time.time()\n",
    "    \n",
    "    last_model = None\n",
    "    last_train_size = None\n",
    "    results = pd.DataFrame()\n",
    "    if start_results is not None:\n",
    "        last_model = start_results['model'].tail(1)\n",
    "        last_size_train = start_results['size_train'].tail(1)\n",
    "        results = start_results\n",
    "    for model in models:\n",
    "            \n",
    "        print(' ', model['name'], end=' ')\n",
    "            \n",
    "        for size_train in sizes_train:\n",
    "            \n",
    "            if start_results is not None:\n",
    "                if model in start_results['model'].unique() and last_size_train >= size_train:\n",
    "                        continue\n",
    "            start_results = None\n",
    "            \n",
    "            print('.', end='')\n",
    "\n",
    "            x_train = X[:size_train]\n",
    "            y_train = y[:size_train]\n",
    "\n",
    "            m = model['model']()\n",
    "            start_time = time.time()\n",
    "            m.fit(x_train, y_train)\n",
    "            train_time = time.time() - start_time\n",
    "\n",
    "            start_time = time.time()\n",
    "            result = m.predict(x_test)\n",
    "            test_time = time.time() - start_time\n",
    "            \n",
    "            data = {'datetime': datetime.datetime.now(),\n",
    "                          'model': model['name'],\n",
    "                          'accuracy': accuracy_score(result, y_test),\n",
    "                          'precision': precision_score(result, y_test, average=metric_average),\n",
    "                          'recall': recall_score(result, y_test, average=metric_average),\n",
    "                          'f1': f1_score(result, y_test, average=metric_average),\n",
    "                          'confusion': confusion_matrix(result, y_test),\n",
    "                          'train_size': size_train,\n",
    "                          'execution_time': train_time,\n",
    "                          'test_time': test_time}\n",
    "            results = results.append([data])\n",
    "            results.to_csv(save)\n",
    "    print('')\n",
    "    aux = time.time() - start_benchmark\n",
    "    print('Run time benchmark:', aux)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
