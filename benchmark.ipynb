{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import LinearSVC, SVR\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import keras\n",
    "import nltk\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "\n",
    "patch_wordembedding_dt = '/home/eduardo/word_embedding/wiki.multi.nl.vec'\n",
    "patch_wordembedding_en = '/home/eduardo/word_embedding/wiki.multi.en.vec'\n",
    "patch_wordembedding_es = '/home/eduardo/word_embedding/wiki.multi.es.vec'\n",
    "patch_wordembedding_it = '/home/eduardo/word_embedding/wiki.multi.it.vec'\n",
    "patch_wordembedding_pt = '/home/eduardo/word_embedding/wiki.multi.pt.vec'\n",
    "\n",
    "embedding_dt = None\n",
    "embedding_en = None\n",
    "embedding_es = None\n",
    "embedding_it = None\n",
    "embedding_pt = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature(feature, df, df_2, embedding=None):\n",
    "    if feature == 'bow':\n",
    "        model = CountVectorizer(analyzer='word', strip_accents=None, \n",
    "                                ngram_range=(1, 1), lowercase=True, \n",
    "                                max_features=5000)\n",
    "        model.fit(df['question'])\n",
    "        ret = model.transform(df_2['question']).toarray()\n",
    "        df_2['bow'] = [x for x in ret]\n",
    "\n",
    "    if feature == 'tfidf':\n",
    "        model = TfidfVectorizer(analyzer='word', strip_accents=None, \n",
    "                                ngram_range=(1, 1), lowercase=True, \n",
    "                                max_features=5000)\n",
    "        model.fit(df['question'])\n",
    "        ret = model.transform(df_2['question']).toarray()\n",
    "        df_2['tfidf'] = [x for x in ret]\n",
    "    \n",
    "    if feature == 'tfidf_3gram':\n",
    "        model = TfidfVectorizer(analyzer='word', strip_accents=None, \n",
    "                                ngram_range=(1, 2), lowercase=True, \n",
    "                                max_features=80000)\n",
    "        model.fit(df['question'])\n",
    "        ret = model.transform(df_2['question']).toarray()\n",
    "        df_2['tfidf'] = [x for x in ret]\n",
    "\n",
    "    if feature == 'embedding':\n",
    "        if embedding is None:\n",
    "            print('Error: embedding None')\n",
    "            return\n",
    "        embds = []\n",
    "        for question in df_2['question']:\n",
    "            tokens = nltk.word_tokenize(question)\n",
    "            embed = []\n",
    "            for token in tokens:\n",
    "                if token.lower() in embedding:\n",
    "                    embed.append(embedding[token.lower()])\n",
    "                else:\n",
    "                    embed.append(np.zeros(300))\n",
    "            embds.append(embed)\n",
    "        df_2['embedding'] = embds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create supervised models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear():\n",
    "    return LinearSVC()\n",
    "\n",
    "def lstm_default(in_dim=300, out_dim=7, drop=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_dim=in_dim, name='0_LSTM'))\n",
    "    model.add(Dropout(drop, name='1_Droupout'))\n",
    "    model.add(Dense(128, activation='relu', name='2_Dense'))\n",
    "    model.add(Dropout(drop, name='3_Droupout'))\n",
    "    model.add(Dense(out_dim, activation='softmax', name='4_Dense'))\n",
    "    otimizer = keras.optimizers.Adam(lr=0.01) #decay = 0.0001\n",
    "    model.compile(optimizer=otimizer, loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "def random_forest():\n",
    "    return RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "def mlp(in_dim=5000, out_dim=7, drop=0.65):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=in_dim, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(out_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(emb_path, nmax=50000):\n",
    "    embedding = {}\n",
    "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        next(f)\n",
    "        for i, line in enumerate(f):\n",
    "            word, vect = line.rstrip().split(' ', 1)\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "            assert word not in embedding, 'word found twice'\n",
    "            embedding[word] = vect\n",
    "            if len(embedding) == nmax:\n",
    "                break\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nearst Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn(position, embedding, K=5):\n",
    "    rank = []\n",
    "    for word in embedding:\n",
    "        rank.append({'word': word, 'score': np.linalg.norm(position-embedding[word])})\n",
    "    list.sort(rank, key= lambda x: x['score'], reverse=True)\n",
    "    return rank[-K:][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark UIUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(model, X, y, x_test, y_test, sizes_train=[], runs=30, save='default.csv', \n",
    "                  metric_average=\"macro\", onehot=None, out_dim=6, epochs=10):\n",
    "    start_benchmark = time.time()\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for size_train in sizes_train:\n",
    "\n",
    "        print('\\n'+str(size_train), end='|')\n",
    "\n",
    "        for run in range(runs):\n",
    "            print('.', end='')\n",
    "            x_train = X[:size_train]\n",
    "            y_train = y[:size_train]\n",
    "\n",
    "            if 'lstm' in model['name'] or 'mlp' in model['name']:\n",
    "                m = model['model'](out_dim=len(onehot.categories_[0]))\n",
    "                start_time = time.time()\n",
    "                m.fit(x_train, y_train, verbose=0, epochs=epochs)\n",
    "                train_time = time.time() - start_time\n",
    "                start_time = time.time()\n",
    "                result = m.predict(x_test)\n",
    "                test_time = time.time() - start_time\n",
    "                #print('  nan:', np.any(np.isnan(result)), end='')\n",
    "                #print('  fin:', np.all(np.isfinite(result)), end='')\n",
    "                result = np.nan_to_num(result)\n",
    "                result = onehot.inverse_transform(result)\n",
    "                y_test_ = onehot.inverse_transform(y_test)\n",
    "            else:\n",
    "                m = model['model']()\n",
    "                start_time = time.time()\n",
    "                m.fit(x_train, y_train)\n",
    "                train_time = time.time() - start_time\n",
    "\n",
    "                start_time = time.time()\n",
    "                result = m.predict(x_test)\n",
    "                test_time = time.time() - start_time\n",
    "                y_test_ = y_test\n",
    "\n",
    "            data = {'datetime': datetime.datetime.now(),\n",
    "                    'model': model['name'],\n",
    "                    'accuracy': accuracy_score(result, y_test_),\n",
    "                    'precision': precision_score(result, y_test_, average=metric_average),\n",
    "                    'recall': recall_score(result, y_test_, average=metric_average),\n",
    "                    'f1': f1_score(result, y_test_, average=metric_average),\n",
    "                    'mcc': matthews_corrcoef(result, y_test_),\n",
    "                    'confusion': confusion_matrix(result, y_test_),\n",
    "                    'run': run + 1,\n",
    "                    'train_size': size_train,\n",
    "                    'execution_time': train_time,\n",
    "                    'test_time': test_time}\n",
    "            results = results.append([data])\n",
    "            results.to_csv(save)\n",
    "    print('')\n",
    "    aux = time.time() - start_benchmark\n",
    "    print('Run time benchmark:', aux)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uiuc(language):\n",
    "    # language: 'en', 'pt', 'es'\n",
    "    return pd.read_csv('datasets/UIUC_' + language + '/train.csv'), pd.read_csv('datasets/UIUC_' + language + '/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run UIUC Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM + WordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in ['pt']:\n",
    "    print('\\n\\nLanguage: ', language)\n",
    "    embedding = load_embedding('/home/eduardo/word_embedding/wiki.multi.' + language + '.vec')\n",
    "    dataset_train, dataset_test = load_uiuc(language)\n",
    "    create_feature('embedding', dataset_train, dataset_train, embedding)\n",
    "    create_feature('embedding', dataset_train, dataset_test, embedding)\n",
    "    model = {'name': 'lstm', 'model': lstm_default}\n",
    "    X_train = np.array([list(x) for x in dataset_train['embedding'].values])\n",
    "    X_test = np.array([list(x) for x in dataset_test['embedding'].values])\n",
    "    X_train = pad_sequences(X_train, maxlen=12, dtype='float', padding='post', truncating='post', value=0.0)\n",
    "    X_test = pad_sequences(X_test, maxlen=12, dtype='float', padding='post', truncating='post', value=0.0)\n",
    "    y_train = dataset_train['class'].values\n",
    "    y_test = dataset_test['class'].values\n",
    "#     y_train_sub = dataset_train['sub_class'].values\n",
    "#     sub_classes = set()\n",
    "#     for sc in y_train_sub:\n",
    "#         sub_classes.add(sc)\n",
    "#     y_test_sub = dataset_test['sub_class'].values\n",
    "#     X_test_sub_ = []\n",
    "#     y_test_sub_ = []\n",
    "#     for i in range(len(X_test)):\n",
    "#         if y_train_sub[i] in sub_classes:\n",
    "#             X_test_sub_.append(X_test[i])\n",
    "#             y_test_sub_.append(y_train_sub[i])\n",
    "#     X_test_sub_ = np.array(X_test_sub_)\n",
    "#     y_test_sub_ = np.array(y_test_sub_)\n",
    "    ohe = OneHotEncoder()\n",
    "    y_train = ohe.fit_transform([[y_] for y_ in y_train]).toarray()\n",
    "    y_test = ohe.transform([[y_] for y_ in y_test]).toarray() \n",
    "    run_benchmark(model, X_train, y_train, X_test, y_test, sizes_train=[1000, 2000, 3000, 4000, 5500],\n",
    "                  runs=30, save='results/UIUC_lstm_embedding_' + language + '.csv', epochs=100, onehot=ohe)\n",
    "    #run_benchmark(model, X_train, y_train_sub, X_test_sub_, y_test_sub_, sizes_train=[1000, 2000, 3000, 4000, 5500],\n",
    "    #              save='results/UIUCsub_svm_tfidf_' + language + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in ['en', 'es', 'pt']:\n",
    "    print('\\n\\nLanguage: ', language)\n",
    "    dataset_train, dataset_test = load_uiuc(language)\n",
    "    create_feature('tfidf', dataset_train, dataset_train, embedding)\n",
    "    create_feature('tfidf', dataset_train, dataset_test, embedding)\n",
    "    model = {'name': 'svm', 'model': svm_linear}\n",
    "    X_train = np.array([list(x) for x in dataset_train['tfidf'].values])\n",
    "    X_test = np.array([list(x) for x in dataset_test['tfidf'].values])\n",
    "    y_train = dataset_train['class'].values\n",
    "    y_test = dataset_test['class'].values\n",
    "    run_benchmark(model, X_train, y_train, X_test, y_test, sizes_train=[1000, 2000, 3000, 4000, 5500],\n",
    "                  save='results/UIUC_svm_tfidf_' + language + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for language in ['en', 'es', 'pt']:\n",
    "    print('\\n\\nLanguage: ', language)\n",
    "    dataset_train, dataset_test = load_uiuc(language)\n",
    "    create_feature('tfidf', dataset_train, dataset_train, embedding)\n",
    "    create_feature('tfidf', dataset_train, dataset_test, embedding)\n",
    "    model = {'name': 'rfc', 'model': random_forest}\n",
    "    X_train = np.array([list(x) for x in dataset_train['tfidf'].values])\n",
    "    X_test = np.array([list(x) for x in dataset_test['tfidf'].values])\n",
    "    y_train = dataset_train['class'].values\n",
    "    y_test = dataset_test['class'].values\n",
    "    run_benchmark(model, X_train, y_train, X_test, y_test, sizes_train=[1000, 2000, 3000, 4000, 5500],\n",
    "                  save='results/UIUC_rfc_tfidf_' + language + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM + TFIDF_3gram + RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Language:  en\n",
      "SKB Start\n",
      "SKB End\n",
      "\n",
      "1000|.\n",
      "2000|.\n",
      "3000|.\n",
      "4000|.\n",
      "5500|.\n",
      "Run time benchmark: 1.2348272800445557\n",
      "\n",
      "\n",
      "Language:  es\n",
      "SKB Start\n",
      "SKB End\n",
      "\n",
      "1000|.\n",
      "2000|.\n",
      "3000|.\n",
      "4000|.\n",
      "5500|.\n",
      "Run time benchmark: 1.5204951763153076\n",
      "\n",
      "\n",
      "Language:  pt\n",
      "SKB Start\n",
      "SKB End\n",
      "\n",
      "1000|.\n",
      "2000|.\n",
      "3000|.\n",
      "4000|.\n",
      "5500|.\n",
      "Run time benchmark: 1.346195936203003\n"
     ]
    }
   ],
   "source": [
    "for language in ['en', 'es', 'pt']:\n",
    "    print('\\n\\nLanguage: ', language)\n",
    "    dataset_train, dataset_test = load_uiuc(language)\n",
    "    create_feature('tfidf_3gram', dataset_train, dataset_train)\n",
    "    create_feature('tfidf_3gram', dataset_train, dataset_test)\n",
    "    model = {'name': 'svm_skb', 'model': svm_linear}\n",
    "    X_train = np.array([list(x) for x in dataset_train['tfidf'].values])\n",
    "    X_test = np.array([list(x) for x in dataset_test['tfidf'].values])\n",
    "    y_train = dataset_train['class'].values\n",
    "    y_test = dataset_test['class'].values\n",
    "    \n",
    "    classes = list(dataset_train['class'].unique())\n",
    "    y_train_ = [classes.index(c) for c in y_train]\n",
    "    \n",
    "    print('SKB Start')\n",
    "    #selector = selector.fit(X_train, y_train_)\n",
    "    skb = SelectKBest(chi2, k=5000).fit(X_train, y_train_)\n",
    "    X_train = skb.transform(X_train)\n",
    "    X_test = skb.transform(X_test)\n",
    "    print('SKB End')\n",
    "    \n",
    "    run_benchmark(model, X_train, y_train, X_test, y_test, sizes_train=[1000, 2000, 3000, 4000, 5500],\n",
    "                  runs=1, save='results/UIUC_svm_skb_tfidf3gram_' + language + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISEQuA Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(model, X, y, folds=10, save='default.csv', sizes_train=[],\n",
    "                  start_results=None, metric_average=\"macro\", onehot=None):\n",
    "    \n",
    "    start_benchmark = time.time()\n",
    "    results = pd.DataFrame()\n",
    "    for size_train in sizes_train:\n",
    "        print('\\n'+str(size_train)+'|', end='')\n",
    "        size_test = len(X) - size_train\n",
    "        rs = ShuffleSplit(n_splits=folds, train_size=size_train, test_size=size_test)\n",
    "        fold = 0\n",
    "        for train_indexs, test_indexs in rs.split(X):\n",
    "            print('.', end='')\n",
    "            x_train = X[train_indexs]\n",
    "            y_train = y[train_indexs]\n",
    "            x_test = X[test_indexs]\n",
    "            y_test = y[test_indexs]\n",
    "\n",
    "            if 'lstm' in model['name']:\n",
    "                m = model['model']()\n",
    "                start_time = time.time()\n",
    "                m.fit(x_train, y_train, verbose=0, epochs=100)\n",
    "                train_time = time.time() - start_time\n",
    "\n",
    "                start_time = time.time()\n",
    "                result = m.predict(x_test)\n",
    "                test_time = time.time() - start_time\n",
    "                result = onehot.inverse_transform(result)\n",
    "                y_test = onehot.inverse_transform(y_test)\n",
    "            else:\n",
    "                m = model['model']()\n",
    "                start_time = time.time()\n",
    "                m.fit(x_train, y_train)\n",
    "                train_time = time.time() - start_time\n",
    "\n",
    "                start_time = time.time()\n",
    "                result = m.predict(x_test)\n",
    "                test_time = time.time() - start_time\n",
    "\n",
    "            data = {'datetime': datetime.datetime.now(),\n",
    "                    'accuracy': accuracy_score(result, y_test),\n",
    "                    'precision': precision_score(result, y_test, average=metric_average),\n",
    "                    'recall': recall_score(result, y_test, average=metric_average),\n",
    "                    'f1': f1_score(result, y_test, average=metric_average),\n",
    "                    'confusion': confusion_matrix(result, y_test),\n",
    "                    'train_size': size_train,\n",
    "                    'fold': fold,\n",
    "                    'execution_time': train_time,\n",
    "                    'test_time': test_time}\n",
    "            results = results.append([data])\n",
    "            results.to_csv(save)\n",
    "            fold += 1\n",
    "    print('')\n",
    "    aux = time.time() - start_benchmark\n",
    "    print('Run time benchmark:', aux)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_disequa(language):\n",
    "    df = pd.read_csv('datasets/DISEQuA/disequa.csv')\n",
    "    return df[df['language'] == language]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN DISEQuA Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in ['DUT', 'ENG', 'ITA', 'SPA']:\n",
    "    print('\\n\\nLanguage: ', language)\n",
    "    dataset = load_disequa(language)\n",
    "    create_feature('tfidf', dataset, dataset, embedding)\n",
    "    model = {'name': 'svm', 'model': svm_linear}\n",
    "    X = np.array([list(x) for x in dataset['tfidf'].values])\n",
    "    y = dataset['class'].values\n",
    "    run_benchmark(model, X, y, sizes_train=[100,200,300,400],\n",
    "                  save='results/DISEQuA_svm_tfidf_' + language + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RFC + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in ['DUT', 'ENG', 'ITA', 'SPA']:\n",
    "    print('\\n\\nLanguage: ', language)\n",
    "    dataset = load_disequa(language)\n",
    "    create_feature('tfidf', dataset, dataset, embedding)\n",
    "    model = {'name': 'rfc', 'model': random_forest}\n",
    "    X = np.array([list(x) for x in dataset['tfidf'].values])\n",
    "    y = dataset['class'].values\n",
    "    run_benchmark(model, X, y, sizes_train=[100,200,300,400],\n",
    "                  save='results/DISEQuA_rfc_tfidf_' + language + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM + TFIDF_3gram + SKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Language:  DUT\n",
      "\n",
      "100|..........\n",
      "200|..........\n",
      "300|..........\n",
      "400|..........\n",
      "Run time benchmark: 1.1172964572906494\n",
      "\n",
      "\n",
      "Language:  ENG\n",
      "\n",
      "100|..........\n",
      "200|..........\n",
      "300|..........\n",
      "400|..........\n",
      "Run time benchmark: 1.2064998149871826\n",
      "\n",
      "\n",
      "Language:  ITA\n",
      "\n",
      "100|..........\n",
      "200|..........\n",
      "300|..........\n",
      "400|.........."
     ]
    }
   ],
   "source": [
    "for language in ['DUT', 'ENG', 'ITA', 'SPA']:\n",
    "    print('\\n\\nLanguage: ', language)\n",
    "    dataset = load_disequa(language)\n",
    "    create_feature('tfidf_3gram', dataset, dataset)\n",
    "    model = {'name': 'svm', 'model': svm_linear}\n",
    "    X = np.array([list(x) for x in dataset['tfidf'].values])\n",
    "    y = dataset['class'].values\n",
    "    skb = SelectKBest(chi2, k=2000).fit(X, y)\n",
    "    X = skb.transform(X)\n",
    "    run_benchmark(model, X, y, sizes_train=[100,200,300,400],\n",
    "                  save='results/DISEQuA_svm_tfidf_3gram_' + language + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM + Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language, embd_l in zip(['SPA'], ['es']):\n",
    "    print('\\n\\nLanguage: ', language)\n",
    "    embedding = load_embedding('/home/eduardo/word_embedding/wiki.multi.' + embd_l + '.vec')\n",
    "    dataset = load_disequa(language)\n",
    "    create_feature('embedding', dataset, dataset, embedding)\n",
    "    model = {'name': 'lstm', 'model': lstm_default}\n",
    "    X = np.array([list(x) for x in dataset['embedding'].values])\n",
    "    y = dataset['class'].values\n",
    "    X = pad_sequences(X, maxlen=12, dtype='float', padding='post', truncating='post', value=0.0)\n",
    "    ohe = OneHotEncoder()\n",
    "    y = ohe.fit_transform([[y_] for y_ in y]).toarray()\n",
    "    run_benchmark(model, X, y, sizes_train=[100,200,300,400], onehot=ohe,\n",
    "                  save='results/DISEQuA_lstm_embedding_' + language + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa",
   "language": "python",
   "name": "qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
